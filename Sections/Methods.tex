\section{Methods}
\label{sec:methods}

To incorporate a variety of training setups, covering popular models as well as models targeted to various species groups, we compare a total of 15 pre-trained bioacoustic different feature extractors.
Table \ref{tab:bacpipe_models} shows the different feature extractors along with their model specific training setup. 
As can be seen both self-supervised and supervised learning feature extractors are represented. 
Furthermore, large variations in input length, embedding dimension and training data provide a landscape of feature extractors, allowing us to analyze performance of differently structured embedding spaces.

\subsection{Dataset}
\label{ssub:dataset}

The evaluation datasets that were used for this study are: a bird vocalization dataset (bird dataset) recorded in coffee farms in Colombia and Costa Rica \cite{vega-hidalgo_collection_2023} and a frog vocalization dataset (frog dataset) recorded in Brazil \cite{canas_dataset_2023}.
The recordings in these datasets feature challenging soundscape recordings with overlapping vocalizers and noisy environments.
Both datasets have been reduced from their original size to only include sound events corresponding to classes with more than 150 annotations.
Due to the high amount of polyphony, the frog dataset has furthermore been reduced to only contain sound events with non-overlapping annotations, i.e. turning it into a single-label dataset.
It is worth mentioning, that by excluding overlapping annotations, only polyphony of frog species is removed, overlapping sounds created by insects and birds in the recordings remains.

For the bird dataset this results in 11 classes, while for the frog dataset 18 classes are included in the final dataset.
We intentionally selected soundscape recordings with gradual changes of background noise and overlapping species vocalizations to amplify the differences between the feature extractors' capabilities to structure the data.


\input{Sections/table_models}


\subsection{Data pipeline}
\label{ssub:data_pipe}

For each of the feature extractors, the respective model code base was cloned, and the model was stripped of its classifier.
For both animal2vec feature extractors, outputs from the attention heads and input lengths are averaged, resulting in one embedding per input segment (as is the case with all other feature extractors).
Data is imported from the sound files, resampled to the model specific sample rate and padded to fit the model specific input length.
All the necessary code to reproduce the computations can be found in the repository \textbf{bacpipe}\footnote{\url{github.com/bioacoustic-ai/bacpipe}} (\textbf{b}io\textbf{a}coustic \textbf{c}ollection \textbf{pipe}line).

\subsection{Methods of evaluating embedding spaces}
\label{ssub:eval_dim_reduc}

Embedding spaces are evaluated using clustering and classification.
Our primary focus is the comparison of the two paradigms: supervised learning and self-supervised learning.
Furthermore, we are looking into how the data chosen for training affects the clustering capabilities of different feature extractors.


% Given the high dimensional nature of embedding spaces, any quantitative evaluation may be subject to the curse of dimensionality \cite{bellman_dynamic_1957}.
% This refers to the issues that arise when dealing with comparatively small number of datapoints in very high dimensional space.
% In our setup this is relevant as the dimensions vary greatly and any resulting distance based calculations will be affected differently if they are calculated spaces of varying dimensions. 
% Therefore, we aim to evaluate in what way reducing the dimension of embedding spaces impacts performance for each of the feature extractors.
% The underlying assumption is that by homogenizing the dimension of the very differently structured embedding spaces, we lay the groundwork for quantitatively comparing the different feature extractors.

% % Therefore, we must first assess how reducing the dimension affects the performance of each feature extractor.
% Initially, feature extractor performance will be analysed using clustering performance and subsequently the performance of the reduced embedding spaces will be compared in the same way and related back to the initial performance values.
% We will compare two versions of linear dimensionality reduction algorithms, principal component analysis (PCA) \cite{wold_principal_1987} and sparse principal component analysis (sPCA) \cite{zou_sparse_2006} as well as one non-linear dimensionality reduction algorithm, uniform manifold approximation projection (UMAP) \cite{mcinnes_umap_2020}.
% Clustering performance will be analysed using Silhouette Score (SS) \cite{rousseeuw_silhouettes_1987}, Adjusted Rand Index (AIR) \cite{steinley_variance_2016} and Adjusted Mutual Information (AMI) \cite{romano_standardized_2014}.

% Reducing dimensions using linear transformations has the advantage of preserving relative distances between all data points.
% This means that quantitative analyses involving distance based calculations can be performed in the lower dimensional space.
% Non-linear dimensionality reduction like UMAP however, creates a learned transformation based on a graph structure of the data and therefore disregards distances between data points \cite{mcinnes_umap_2020}.
% While it is claimed that UMAP preserves relative distances for within cluster points, transformed relative distances between clusters are not representative of distances in the original high dimensional space.

% To evaluate the changing embedding spaces as a function of the dimensionality reduction method, clustering performance will be evaluated. Adjusted Rand Index (AIR) \cite{steinley_variance_2016} and  
The clustering is computed using KMeans with the same number of clusters as classes in the ground truth. 
Clustering performance will be evaluated using Adjusted Mutual Information (AMI) \cite{romano_standardized_2014} to compare the KMeans clustering with the ground truth.
Adjusted Rand Index is not included in this study, as it focuses on how well data points are grouped in a clustering, whereas we are primarily interested how well the KMeans clustering agrees with the ground truth labels.
% Non-linear dimensionality reduction algorithms like UMAP create a learned transformation based on a graph structure of the data and therefore disregards distances between data points \cite{mcinnes_umap_2020}.
Silhouette Score is also not included in this comparison as the challenging dataset yielded very low performance and variance, making a meaningful comparison impossible.
% AMI and ARI require a clustering to be computed, to then quantify the agreement between that clustering and the ground truth and are therefore applicable to non-linear dimensionality reductions.
% AMI measures how well clusters share information while ARI quantifies how well points are grouped.

Performance is also evaluated by training a single-layer classifier on each of the embedding spaces.
Classification is performed using a kNN approach with a nearest neighbor parameter of 15.
% The linear classifier is trained on the 11 and 18 classes for the bird and frog datasets respectively for 10 epochs with a batch size of 64 and a learning rate of 0.001. 
% For the kNN classifier a nearest neighbor parameter of 15 is chosen.
The classifier is trained on the 11 and 18 classes for the bird and frog datasets respectively.
Data is split into train, validation and test set in the ratio 0.65:0.15:0.2.
Performance is evaluated using a balanced macro accuracy score \cite{brodersen_balanced_2010} to handle the imbalance in class sizes.

Evaluations are computed in both the original embedding spaces and an embedding space reduced to 300 dimensions.
This way the embedding dimension is standardized and performance can be compared while controlling for this factor.
It also allows us to compare the performance of each model in their high dimensional original embedding space, as well as in a reduced dimension.
% For the linear classifier, to preserve relative distances between data points, Principal Component Analysis (PCA), a linear dimensionality reduction is selected.
Uniform manifold approximation projection (UMAP) \cite{mcinnes_umap_2020} is selected for the dimensionality reduction to 300 dimensions.
UMAP is also used to visualize the embeddings in two dimensions in Fig. \ref{fig:embeds}.